# Redis 单线程和高性能
通常讲 redis 单线程指的是 Redis 的网络 I/O 和指令读写是由一个线程完成的，至于其他的任务，比如持久化、数据同步等就是异步完成的；

虽然网络 I/O 和指令读写是单线程，但是 Redis 是在内存中工作，因此即使是单线程，执行效率也是很高的；其次，Redis I/O 模型采用 epoll 来实现
多路复用，这也是 Redis 能处理那么多并发客户连接的原因；(I/O 模型详见 NIO 章节[NIO](https://github.com/an-1024/Middleware_St/blob/master/nio/src/main/resources/note/1.NIOBIO.md))

# Redis 持久化
刚才也提到过，Redis 是工作在内存中的，所有的数据也在内存中。所以一旦服务器宕机，Redis 缓存的数据就会全部丢失。因此 Redis 针对于这种情况实现
了两种持久化机制：RDB(快照：全量备份)、AOF(增量备份)。
## RDB 快照
在默认情况下，Redis 将内存数据快照保存在名为 dump.rdb 文件中。可以通过修改 redis.conf 文件参数 `save` 来设置多长时间内，修改多少次进行一次
保存。如`save 60 1000`，60秒内至少有1000个键被修改，就会自动保存一次。

1. 数据丢失问题：这个保存很明显会暴露出一个问题，就是在达到这个触发节点的时候，Redis 宕机，数据就会丢失。
2. 时点性问题：写入数据需要时间，比如 8点开始写入数据，需要4s写入，那么最终存入磁盘的数据是哪一刻的呢？
3. 效率问题：在服务线上请求的同时，Redis 还需要进行内存快照，内存快照要求 Redis 必须进行文 件 IO 操作，可文件 IO 操作是不能使用多路复用 API。

先来谈谈 2、3 问题。Redis 为了解决这样的问题，采用操作系统的写时复制技术(Copy-On-Write,COW)，就是从父进程中 fork 一个子进程，子进程完全可以共享
父进程的数据，如果父进程是对数据进行读操作，对于子进程没有影响，直接向磁盘写入数据。如果是写操作，那么父进程会将那一刻的数据复制出一份出来，然后在新的
数据上进行修改，而子进程写入的数据还是操作数据之前那一刻的数据。因此问题 2 中写入的数据是 fork 子进程那一刻的。

## AOF(增量备份)
AOF 就是为了解决 RDB 数据丢失的问题。AOF 会将修改的每一条指令记录进文件appendonly.aof中(先写入os cache，每隔一段时间 fsync到磁盘)。可以
通过参数`# appendonly yes` 进行控制。打开这个机制后，每当 redis 修改一个数据集，这个命令就会被追加到这个文件的末尾。这样即使 redis 宕机，
也可以通过 aof 文件进行数据恢复。同样 redis 也提供了配置策略：
```shell
appendfsync always # 每次有新命令追加到 AOF 文件时就执行一次 fsync ，非常慢，也非常安全。
appendfsync everysec # 每秒 fsync 一次，足够快，并且在故障时只会丢失 1 秒钟的数据。
appendfsync no # 从不 fsync ，将数据交给操作系统来处理。更快，也更不安全的选择。
```

## fsync 
Linux 的 glibc 提供了 fsync(int fd)函数可以将指定文件的内容强制从内核缓存刷到磁 盘。只要 Redis 进程实时调用 fsync 函数就可以保证 aof 
日志不丢失。但是 fsync 是一个 磁盘 IO 操作，它很慢!如果 Redis 执行一条指令就要 fsync 一次，那么 Redis 高性能的 地位就不保了。 所以在
生产环境的服务器中，Redis 通常是每隔 1s 左右执行一次 fsync 操作，周期 1s 是可以配置的。这是在数据安全性和性能之间做了一个折中，在保持
高性能的同时，尽可能 使得数据少丢失。

redis 在业务长期运行期间，AOF的日志肯定会变得很长很长🤮。如果实例宕机，那么使用 AOF 恢复的时候，会导致 Redis 长时间无法对外提供服务，这显然
是不能容忍的。所以需要对 AOF 进行瘦身。

### AOF 日志瘦身
Redis 提供了 bgrewriteaof 指令用于对 AOF 日志进行瘦身。其原理就是开辟一个子进程对内存进行遍历转换成一系列 Redis 的操作指令，
序列化到一个新的 AOF 日志文件中。做法就是去掉相同键值无用的指令，只保持对该 key 操作的最新指令。

## 小结
1. 快照：快照是通过开启子进程的方式进行的，它是一个比较耗资源的操作，遍历整个内存，大块写磁盘会加重系统负载；
2. AOF：fsync 是一个耗时的 IO 操作，它会降低 Redis 性能，同时也会增加系统 IO 负担；

所以通常 Redis 的主节点是不会进行持久化操作，持久化操作主要在从节点进行。从节 点是备份节点，没有来自客户端请求的压力，它的操作系统资源
往往比较充沛。

## Redis 4.0 混合持久化
上面提到过，RDB 容易丢失大量数据，一般使用 aof 恢复，但是 aof 恢复数据相比于 rdb 来说要慢很多，在 redis 实例较大的情况下，启动很慢。为了
解决这样的问题，Redis 4.0 带来了一个新的持久化选项——混合持久化。将 RDB 文件和增量的 aof 日志文件放到一起。注意这里的 aof 日志不再是全量的
日志了，而是自持久化开始到持久化结束这一段时间日志的增量。

## Redis 数据备份策略
1. 写crontab定时调度脚本，每小时都copy一份rdb或aof的备份到一个目录中去，仅仅保留最近48 小时的备份
2. 每天都保留一份当日的数据备份到一个目录中去，可以保留最近1个月的备份
3. 每次copy备份的时候，都把太旧的备份给删了
4. 每天晚上将当前机器上的备份复制一份到其他机器上，以防机器损坏

# Redis 主从架构
## 主从配置
主节点配置信息如下：
```text
# 指定本机通过本机的哪一个 ip 地址来接收外部请求，而不是允许那个 ip 访问
bind 0.0.0.0
# 关闭保护模式
protected-mode no
# 设置 port 端口
port 6379
# 设置后台运行
daemonize yes
# 保存 redis 运行的 pid, 进程结束后会自动删除
pidfile /var/run/redis_6379.pid
# 生成日志文件名称
logfile "redis_6379.log"
# 指定生成备份数据的文件目录
dir /root/Dev_Azh/redis/data/6379
```
从节点配置如下：
```text
# 指定本机通过本机的哪一个 ip 地址来接收外部请求，而不是允许那个 ip 访问
bind 0.0.0.0
# 关闭保护模式
protected-mode no
# 设置 port 端口
port 6380
# 设置后台运行
daemonize yes
# 保存 redis 运行的 pid, 进程结束后会自动删除
pidfile /var/run/redis_6380.pid
# 生成日志文件名称
logfile "redis_6380.log"
# 指定生成备份数据的文件目录
dir /root/Dev_Azh/redis/data/6380
# 指定主节点连接 ip
replicaof 10.211.55.3 6379
```

第二个从节点配置如下：
```text
# 指定本机通过本机的哪一个 ip 地址来接收外部请求，而不是允许那个 ip 访问
bind 0.0.0.0
# 关闭保护模式
protected-mode no
# 设置 port 端口
port 6381
# 设置后台运行
daemonize yes
# 保存 redis 运行的 pid, 进程结束后会自动删除
pidfile /var/run/redis_6381.pid
# 生成日志文件名称
logfile "redis_6381.log"
# 指定生成备份数据的文件目录
dir /root/Dev_Azh/redis/data/6381
# 指定主节点连接 ip
replicaof 10.211.55.3 6379
```
关闭防火墙
```shell
# 查看防火墙状态
firewall-cmd --state
# 停止防火墙
systemctl stop firewalld.service
# 禁止防火墙开机启动
systemctl disable firewalld.service 
```


开始启动实例
```shell
# 启动主节点实例
redis-server redis_6379.conf 
# 查看服务是否启动成功
ps ‐ef | grep redis
# 结果：
root      1599     1  0 20:27 ?        00:00:00 redis-server 0.0.0.0:6379

# 启动从节点实例
redis-server redis_6380.conf 
redis-server redis_6381.conf

# 在主节点上使用客户端连接 redis，并设置数据
redis-cli -p 6379
# 设置数据
127.0.0.1:6379> set master:10.211.55.3 "master"
# 此时连接两个从节点客户端，查看数据是否同步
redis-cli -p 6380
127.0.0.1:6380> keys *
# 输出结果：
1) "master:10.211.55.3"

redis-cli -p 6381
127.0.0.1:6381> keys *
1) "master:10.211.55.3"
```
至此主从结构搭建成功。


## Reids 主从工作原理
主从复制过程大体可以分为3个阶段：连接建立阶段（即准备阶段）、数据同步阶段、命令传播阶段。

1. 连接建立阶段：
   1. 先在缓存中保存 master 节点信息；日志信息如下：
   ```shell
   efore turning into a replica, using my master parameters to synthesize a cached master: I may be able to synchronize 
   with the new master with just a partial transfer
   ```
   2. 建立 socket 长连接；日志信息如下：
   ```shell
   Connecting to MASTER 10.211.55.3:6379
   MASTER <-> REPLICA sync started
   ```
   3. 发送 ping 命令确认主机网络畅通；
   ```shell
   Master replied to PING, replication can continue...
   ```
2. 数据同步阶段:
   1. 从节点启动，总会向 master 发送一个 psync(2.8以前发送 sync 命令) 命令到 master 请求复制数据；
   2. 主节点收到 psync 命令会在后台进行数据持久化通过bgsave生成最新的rdb快照文件, 持久化期间仍然会接收客户端的请求；
   3. 在持久化期间，master会将接收到可能修改数据集的命令缓存到内存中；
   4. master 持久化完成后，会将 rdb 文件数据集发给 slave 节点，slave 会先将这些数据生成 rdb 文件，然后再加载到内存中；
   5. 接着master会将之前加载到缓存中的命令发送给 slave
3. 命令传播阶段：
   1. 数据同步阶段完成后，主从节点进入命令传播阶段；在这个阶段主节点将自己执行的写命令发送给从节点，从节点接收命令并执行，从而保证主从节点数据的一致性。
      
注意：当master与slave之间的连接由于某些原因而断开时，slave能够自动重连Master，如果master收到了多 个slave并发连接请求，它只会进行一
次持久化，而不是一个连接一次，然后再把这一份持久化的数据发送 给多个并发连接的slave。

主从同步原理图(全量数据复制)：
![](../photo/1.主从原理图.png)

### 数据部分复制
从节点断开与主节点的连接，再次连接的时候，一般都会对数据进行全量复制。从redis2.8开始，master和它所有的 slave都维护了复制的数据下标
offset和master的进程id，因此，当网络连接断开后，slave会请求master 继续进行未完成的复制，从所记录的数据下标开始。如果master进程id变化了，
或者从节点数据下标 offset 太旧，已经不在master的缓存队列里了，那么将会进行一次全量数据的复制。这种机制就叫**断点续传**

如图所示：
![](../photo/2.主从复制-断点续传.png)
注意：如果有很多从节点，为了缓解主从复制风暴(多个从节点同时复制主节点导致主节点压力过大)，可以做如下架构，让部分从节点与从节点(与主节点同步)
同步数据。

# Jedis 连接代码实例
引入相关依赖
```xml
   <dependency>
      <groupId>redis.clients</groupId>
      <artifactId>jedis</artifactId>
      <version>2.9.0</version>
   </dependency>
```

程序 demo
```java
public class JedisDemo {
    public static void main(String[] args) throws IOException {
        JedisPoolConfig jedisPoolConfig = new JedisPoolConfig();
        jedisPoolConfig.setMaxTotal(20);
        jedisPoolConfig.setMaxIdle(10);
        jedisPoolConfig.setMinIdle(5);

        // timeout，这里既是连接超时又是读写超时，从Jedis 2.8开始有区分connectionTimeout和soTimeo t的构造函数
        JedisPool jedisPool = new JedisPool(jedisPoolConfig, "10.211.55.3", 6379, 3000, null);
        Jedis jedis = null;
        
        try{
            //从redis连接池里拿出一个连接执行命令
            jedis = jedisPool.getResource();
            System.out.println(jedis.set("single", "zhuge"));
            System.out.println(jedis.get("single"));
            //管道示例
            //管道的命令执行方式:cat redis.txt | redis‐cli ‐h 127.0.0.1 ‐a password ‐ p 6379 ‐‐pipe
            /*Pipeline pl = jedis.pipelined();
            for(inti=0;i<10;i++){
                pl.incr("pipelineKey");
                pl.set("zhuge" + i, "zhuge");
            }
             */
            //lua脚本模拟一个商品减库存的原子操作
            //lua脚本命令执行方式:redis‐cli ‐‐eval /tmp/test.lua , 10
            /*jedis.set("product_count_10016", "15"); //初始化商品10016的库存*/
            String script = " local count = redis.call('get', KEYS[1]) " + " local a = tonumber(count) " +
                    " local b = tonumber(ARGV[1]) " + "ifa>=bthen" + " redis.call('set', KEYS[1], a‐b) " +
                    "end" + " return 0 ";
            Object obj = jedis.eval(script, Arrays.asList("product_count_10016"), Arrays.asList("10"));
            System.out.println(obj);
        }catch (Exception e){
            //注意这里不是关闭连接，在JedisPool模式下，Jedis会被归还给资源池。
            if (jedis != null){
                jedis.close();
            }
        }
    }
}
```
# 管道(Pipeline)
客户端可以一次性发送多个请求而不用等待服务器的响应，待所有命令都发送完后再一次性读取服务的响应，这样可以极大的降低多条命令执行的网络传输
开销，管道执行多条命令的网络开销实际上只相当于一次命令执行的网络开销。需要注意到是用pipeline方式打包命令发送，redis必须在处理完所有命令
前先缓存起所有命令的处理结果。打包的命令越多，缓存消耗内存也越多。所以并不是打包的命令越多越好。pipeline中发送的每个command都会被
server立即执行，如果执行失败，将会在此后的响应中得到信息;也就是pipeline并不是表达“所有command都一起成功”的语义，管道中前面命令失败，
后面命令不会有影响，继续执行。

```java
package com.anzhi.masterslavejedis;

public class JedisMasterSlaveDemo {
    public static void main(String[] args) throws IOException {
        JedisPoolConfig jedisPoolConfig = new JedisPoolConfig();
        jedisPoolConfig.setMaxTotal(20);
        jedisPoolConfig.setMaxIdle(10);
        jedisPoolConfig.setMinIdle(5);

        // timeout，这里既是连接超时又是读写超时，从Jedis 2.8开始有区分connectionTimeout和soTimeo t的构造函数
        JedisPool jedisPool = new JedisPool(jedisPoolConfig, "10.211.55.3", 6379, 3000, null);
        Jedis jedis = null;
        
        try{
            //从redis连接池里拿出一个连接执行命令
            jedis = jedisPool.getResource();
            System.out.println(jedis.set("single", "zhuge"));
            System.out.println(jedis.get("single"));
            //管道示例
            //管道的命令执行方式:cat redis.txt | redis‐cli ‐h 127.0.0.1 ‐a password ‐ p 6379 ‐‐pipe
            Pipeline pl = jedis.pipelined();
            for(int i=0;i<10;i++){
                pl.incr("pipelineKey");
                pl.set("zhangsan" + i, "zhuge");
                // 模拟管道报错
                pl.setbit("zhangsan", -1, true);
            }
            List<Object> results=pl.syncAndReturnAll();
            System.out.println(results);
        }catch (Exception e){
            //注意这里不是关闭连接，在JedisPool模式下，Jedis会被归还给资源池。
            if (jedis != null){
                jedis.close();
            }
        }
    }
}
```
Redis 2.6 推出了脚本功能，允许开发者使用Lua语言编写脚本传到Redis中执行。使用脚本的好处如下：
1. **减少网络开销**：本来5次网络请求的操作，可以用一个请求完成，原先5次请求的逻辑放在redis服务器 上完成。使用脚本，减少了网络往返时延。这点跟管道类似。
2. **原子操作**：Redis会将整个脚本作为一个整体执行，中间不会被其他命令插入。管道不是原子的，不过 redis的批量操作命令(类似mset)是原子的。
3. **替代redis的事务功能**:redis自带的事务功能很鸡肋，而redis的lua脚本几乎实现了常规的事务功能， 官方推荐如果要使用redis的事务功能可以用redis lua替代。

# Redis 哨兵高可用架构
主从架构一旦主节点挂了，就需要人工去维护，这肯定是我们不能接受的。Redis 有专门的 Sentinel 监控机制。下面来搭建一下哨兵集群。
配置 sentinel.conf 文件

主节点的 sentinel 配置
```text
# port 端口修改
port 26379
# 设置后台运行
daemonize yes
# 设置保存 redis-sentinel 进程id的文件名称
pidfile /var/run/redis-sentinel-26379.pid
# 设置保存日志文件的名称
logfile "redis-sentinel-26379.log"
# 设置保存数据的文件目录
dir /root/Dev_Azh/redis/data/26379
# 设置要监控的主节点
sentinel monitor mymaster 10.211.55.3 6379 2
```

从节点 sentinel 的配置
```text
# port 端口修改
port 26380
# 设置后台运行
daemonize yes
# 设置保存 redis-sentinel 进程id的文件名称
pidfile /var/run/redis-sentinel-26380.pid
# 设置保存日志文件的名称
logfile "redis-sentinel-26380.log"
# 设置保存数据的文件目录
dir /root/Dev_Azh/redis/data/26380
# 设置要监控的主节点
sentinel monitor mymaster 10.211.55.3 6379 2

# port 端口修改
port 26381
# 设置后台运行
daemonize yes
# 设置保存 redis-sentinel 进程id的文件名称
pidfile /var/run/redis-sentinel-26381.pid
# 设置保存日志文件的名称
logfile "redis-sentinel-26381.log"
# 设置保存数据的文件目录
dir /root/Dev_Azh/redis/data/26381
# 设置要监控的主节点
sentinel monitor mymaster 10.211.55.3 6379 2
```

上面我们已经配置好了主从节点的集群，那个配置都不需要改。在启动主从集群之后，再启动 sentinel 监控
```shell
# 启动主节点监控
redis-sentinel sentinel_26379.conf
redis-sentinel sentinel_26380.conf 
redis-sentinel sentinel_26381.conf

# 查看是否启动成功：
ps -ef | grep redis
root      1772     1  0 21:09 ?        00:00:04 redis-sentinel *:26379 [sentinel]
root      1880     1  0 21:27 ?        00:00:00 redis-server 0.0.0.0:6379

# 客户端连接 sentinel 服务
redis-cli -p 26379
# 用 info 查看信息
# Sentinel
sentinel_masters:1
sentinel_tilt:0
sentinel_running_scripts:0
sentinel_scripts_queue_length:0
sentinel_simulate_failure_flags:0
master0:name=mymaster,status=ok,address=10.211.55.4:6380,slaves=2,sentinels=3
```
可以看到当前主节点是 10.211.55.4, 那么将主节点挂掉，验证故障转移：
```text
# 在主节点对应的虚机上将redis服务 kill
ps -ef | grep redis
root      1610     1  0 20:28 ?        00:00:06 redis-server 0.0.0.0:6380
root      1768     1  0 21:04 ?        00:00:05 redis-sentinel *:26380 [sentinel]
root      1891  1585  0 21:33 pts/0    00:00:00 grep --color=auto redis

# 杀死进程
kill -9 1610

# 在该主机上连接 sentinel 服务
redis-cli -p 26380
# 查看主节点信息
127.0.0.1:26379> info

# Sentinel
sentinel_masters:1
sentinel_tilt:0
sentinel_running_scripts:0
sentinel_scripts_queue_length:0
sentinel_simulate_failure_flags:0
master0:name=mymaster,status=ok,address=10.211.55.3:6379,slaves=2,sentinels=3
```
可以看到主节点从 10.211.55.4 变成了 10.211.55.3 这个节点。

# 代码验证
pom.xml 依赖
```xml
<?xml version="1.0" encoding="UTF-8"?>
<project xmlns="http://maven.apache.org/POM/4.0.0"
         xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
         xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd">
    <modelVersion>4.0.0</modelVersion>

    <groupId>org.example</groupId>
    <artifactId>redis</artifactId>
    <version>1.0-SNAPSHOT</version>

    <parent>
        <groupId>org.springframework.boot</groupId>
        <artifactId>spring-boot-starter-parent</artifactId>
        <version>2.3.1.RELEASE</version>
        <relativePath/> <!-- lookup parent from repository -->
    </parent>

    <properties>
        <maven.compiler.source>8</maven.compiler.source>
        <maven.compiler.target>8</maven.compiler.target>
    </properties>
    
    <dependencies>
        <dependency>
            <groupId>org.springframework.boot</groupId>
            <artifactId>spring-boot-starter-web</artifactId>
        </dependency>

        <dependency>
            <groupId>org.springframework.boot</groupId>
            <artifactId>spring-boot-starter-data-redis</artifactId>
        </dependency>

        <dependency>
            <groupId>org.apache.commons</groupId>
            <artifactId>commons-pool2</artifactId>
        </dependency>

        <dependency>
            <groupId>org.springframework.boot</groupId>
            <artifactId>spring-boot-starter-test</artifactId>
            <scope>test</scope>
        </dependency>
        
        <dependency>
            <groupId>redis.clients</groupId>
            <artifactId>jedis</artifactId>
            <version>2.9.0</version>
        </dependency>
    </dependencies>

    <build>
        <plugins>
            <plugin>
                <groupId>org.springframework.boot</groupId>
                <artifactId>spring-boot-maven-plugin</artifactId>
            </plugin>
        </plugins>
    </build>

</project>
```

yaml 文件配置
```yaml
server:
  port: 8080
  
spring:
  redis:
    database: 0
    timeout: 3000
    sentinel:
      master: mymaster
      nodes: 10.211.55.3:26379,10.211.55.4:26380,10.211.55.5:26381
    lettuce:
      pool:
        max-idle: 50
        min-idle: 10
        max-active: 100
        max-wait: 1000
```

连接redis demo
```java
package com.anzhi.sentineljedis.service;

import redis.clients.jedis.HostAndPort;
import redis.clients.jedis.Jedis;
import redis.clients.jedis.JedisPoolConfig;
import redis.clients.jedis.JedisSentinelPool;

import java.util.HashSet;
import java.util.Set;

public class JedisSentinelDemo {
    public static void main(String[] args) {
        JedisPoolConfig config = new JedisPoolConfig();
        config.setMaxTotal(20);
        config.setMaxIdle(10);
        config.setMinIdle(5);

        String masterName = "mymaster";
        Set<String> sentinels = new HashSet<String>();
        sentinels.add(new HostAndPort("10.211.55.3",26379).toString());
        sentinels.add(new HostAndPort("10.211.55.4",26380).toString());
        sentinels.add(new HostAndPort("10.211.55.5",26381).toString());

        //JedisSentinelPool其实本质跟JedisPool类似，都是与redis主节点建立的连接池
        //JedisSentinelPool并不是说与sentinel建立的连接池，而是通过sentinel发现redis主节点并与其建立连接
        JedisSentinelPool jedisSentinelPool = new JedisSentinelPool(masterName, sentinels, config, 3000, null);
        Jedis jedis = null;
        try{
            jedis = jedisSentinelPool.getResource();
            System.out.println(jedis.set("sentinel", "masterA"));
            System.out.println(jedis.get("sentinel"));
            System.out.println(jedis.del("sentinel"));
        }catch (Exception e){
            // doNothing
        }finally {
            //注意这里不是关闭连接，在JedisPool模式下，Jedis会被归还给资源池。
            if (jedis != null){
                jedis.close();
            }
        }
    }
}
```
Controller 层接口
```java
package com.anzhi.sentineljedis.controller;

import org.slf4j.Logger;
import org.slf4j.LoggerFactory;
import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.data.redis.core.StringRedisTemplate;
import org.springframework.web.bind.annotation.RequestMapping;
import org.springframework.web.bind.annotation.RestController;

@RestController
public class SentinelIndexCOntroller {
    private static final Logger logger = LoggerFactory.getLogger(SentinelIndexCOntroller.class);
    @Autowired
    private StringRedisTemplate stringRedisTemplate;

    /**
     * 测试节点挂了哨兵重新选举新的master节点，客户端是否能动态感知到
     *
     * @throws InterruptedException
     */
    @RequestMapping("/test_sentinel")
    public void testSentinel() throws InterruptedException {
        int i = 1;
        while (true){
            try{
                stringRedisTemplate.opsForValue().set("master"+i, i+""); //jedis.set(key,value);
                System.out.println("设置key："+ "master" + i);
                Thread.sleep(10000);
                stringRedisTemplate.delete("master" + i);
                i++;
            }catch (Exception e){
                logger.error("错误：", e);
            }
        }
    }
}
```
这段程序主要干的事儿是：先设置键值，然后休眠10，在删除 key。一直循环

启动类
```java
package com.anzhi.sentineljedis;

import org.springframework.boot.SpringApplication;
import org.springframework.boot.autoconfigure.SpringBootApplication;

@SpringBootApplication
public class SentinelApplication {
    public static void main(String[] args) {
        SpringApplication.run(SentinelApplication.class, args);
    }
}
```
程序启动后，通过链接 http://localhost:8080/test_sentinel 访问。此时控制台会输出：
```text
设置key：master1
设置key：master2
设置key：master3
设置key：master4
设置key：master5
设置key：master6
设置key：master7
设置key：master8
设置key：master9
```
接下来我们关闭主节点，此时控制台输出：
```text
2023-03-02 21:44:51.256  INFO 11153 --- [xecutorLoop-1-3] i.l.core.protocol.ConnectionWatchdog     : Reconnecting, last destination was /10.211.55.5:6381
2023-03-02 21:44:51.376  WARN 11153 --- [ioEventLoop-4-4] i.l.core.protocol.ConnectionWatchdog     : Cannot reconnect to [10.211.55.5:6381]: Connection refused: /10.211.55.5:6381
2023-03-02 21:44:57.259  INFO 11153 --- [xecutorLoop-1-9] i.l.core.protocol.ConnectionWatchdog     : Reconnecting, last destination was 10.211.55.5:6381
2023-03-02 21:44:57.365  WARN 11153 --- [oEventLoop-4-10] i.l.core.protocol.ConnectionWatchdog     : Cannot reconnect to [10.211.55.5:6381]: Connection refused: /10.211.55.5:6381
2023-03-02 21:45:03.865 ERROR 11153 --- [nio-8080-exec-1] c.a.s.c.SentinelIndexCOntroller          : 错误：

org.springframework.dao.QueryTimeoutException: Redis command timed out; nested exception is io.lettuce.core.RedisCommandTimeoutException: Command timed out after 3 second(s)
```
可以看到，主节点故障，导致程序异常。在程序运行了一段时间后，重新连接到了主节点：
```text
2023-03-02 21:45:26.460  INFO 11153 --- [xecutorLoop-1-8] i.l.core.protocol.ConnectionWatchdog     : Reconnecting, last destination was 10.211.55.5:6381
2023-03-02 21:45:26.466  INFO 11153 --- [oEventLoop-4-16] i.l.core.protocol.ReconnectionHandler    : Reconnected to 10.211.55.3:6379
设置key：master9
设置key：master10
```
但是此时主节点已经发生了变化，变成了 10.211.55.3:6379，然后程序继续运行。




